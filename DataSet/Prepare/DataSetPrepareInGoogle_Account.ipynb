{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGKVvTC33NXqdvzF2LbA6R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThanuMahee12/ayush-vision/blob/data-prepare/DataSet/Prepare/DataSetPrepareInGoogle_Account.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab"
      ],
      "metadata": {
        "id": "yRAdujFDwHSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth"
      ],
      "metadata": {
        "id": "zhOjl2xfxAb7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build"
      ],
      "metadata": {
        "id": "Y-vwxfKMxKSI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "38boXpiAxBmA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DYZBWDtix78f",
        "outputId": "c4eb6bdb-9fe8-4aa2-d0c9-6dc8bf5b7e5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_key='/content/drive/MyDrive/ServiceKey.json'"
      ],
      "metadata": {
        "id": "GZdLNrDgy-nV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_count=1"
      ],
      "metadata": {
        "id": "A8cfmI97zTg7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### user"
      ],
      "metadata": {
        "id": "BBKpdxhiw68G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "service = build('oauth2', 'v2')\n",
        "user_info = service.userinfo().get().execute()\n",
        "email = user_info['email']\n",
        "profile=user_info['picture']\n"
      ],
      "metadata": {
        "id": "XtOqIGaZrwc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Firebase"
      ],
      "metadata": {
        "id": "jBf2MG5iwLqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install firebase-admin"
      ],
      "metadata": {
        "id": "FTNSwya2wdI1",
        "outputId": "c1062e5b-9328-43e1-f68a-8148d1e300c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: firebase-admin in /usr/local/lib/python3.10/dist-packages (6.5.0)\n",
            "Requirement already satisfied: cachecontrol>=0.12.6 in /usr/local/lib/python3.10/dist-packages (from firebase-admin) (0.14.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.7.8 in /usr/local/lib/python3.10/dist-packages (from firebase-admin) (2.137.0)\n",
            "Requirement already satisfied: google-cloud-storage>=1.37.1 in /usr/local/lib/python3.10/dist-packages (from firebase-admin) (2.8.0)\n",
            "Requirement already satisfied: pyjwt>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.5.0->firebase-admin) (2.9.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=1.22.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-firestore>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from firebase-admin) (2.16.1)\n",
            "Requirement already satisfied: requests>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from cachecontrol>=0.12.6->firebase-admin) (2.32.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from cachecontrol>=0.12.6->firebase-admin) (1.0.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.65.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.24.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.27.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.48.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.7.8->firebase-admin) (4.1.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-firestore>=2.9.1->firebase-admin) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage>=1.37.1->firebase-admin) (2.7.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.5.0->firebase-admin) (43.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin) (1.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage>=1.37.1->firebase-admin) (1.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.7.8->firebase-admin) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase-admin) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase-admin) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase-admin) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.16.0->cachecontrol>=0.12.6->firebase-admin) (2024.8.30)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.5.0->firebase-admin) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0dev,>=1.22.1->google-api-core[grpc]<3.0.0dev,>=1.22.1; platform_python_implementation != \"PyPy\"->firebase-admin) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import firebase_admin"
      ],
      "metadata": {
        "id": "2ZmZ8wdZydxW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from firebase_admin import credentials,storage\n"
      ],
      "metadata": {
        "id": "mk3obvVcyf_I"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from firebase_admin import firestore"
      ],
      "metadata": {
        "id": "udGq691jyj5Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if firebase_count==1:\n",
        "  cred = credentials.Certificate(firebase_key)\n",
        "  firebase_admin.initialize_app(cred,{\n",
        "    'storageBucket': 'ayush-vision-asw4gh.appspot.com'\n",
        "})\n",
        "firebase_count=firebase_count+1"
      ],
      "metadata": {
        "id": "K9BN_zA9zQ2B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = firestore.client()"
      ],
      "metadata": {
        "id": "BHxALWW4z9Xc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bucket = storage.bucket()"
      ],
      "metadata": {
        "id": "AsHSO5En0Ayn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_col = db.collection(\"dataset\")"
      ],
      "metadata": {
        "id": "QU2o_Bt50ESo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Default"
      ],
      "metadata": {
        "id": "nc4LUGx-x071"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from datetime import date,datetime\n",
        "import json\n",
        "import csv\n",
        "import yaml"
      ],
      "metadata": {
        "id": "Dbt_VhZIx4MN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_images_in_folder(folder_path):\n",
        "    return sum([len(files) for r, d, files in os.walk(folder_path) if any(file.endswith(('.jpg', '.jpeg', '.png')) for file in files)])\n",
        "\n",
        "def dictory_images_count(root_dir):\n",
        "  train_images = count_images_in_folder(os.path.join(root_dir, 'train','images'))\n",
        "  val_images = count_images_in_folder(os.path.join(root_dir, 'valid','images'))\n",
        "  test_images = count_images_in_folder(os.path.join(root_dir, 'test','images'))\n",
        "  total_images = train_images + val_images + test_images\n",
        "  return {\n",
        "      'total_count':total_images,\n",
        "      'val_count':val_images,\n",
        "      'train_count':train_images,\n",
        "      'test_count':test_images\n",
        "  }"
      ],
      "metadata": {
        "id": "vv6jfXOp-Vtl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yolo"
      ],
      "metadata": {
        "id": "EKcJYIRJrtFk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iNI8uHmBrlqs"
      },
      "outputs": [],
      "source": [
        "Dataset_dir='/content/drive/MyDrive/AyushVision/yolo/dataset'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_doc=dataset_col.document('yolo')\n",
        "doc=yolo_doc.get()"
      ],
      "metadata": {
        "id": "7UXYA-Ukz3mW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not doc.exists:\n",
        "  doc_ref= db.collection(\"dataset\").document('yolo')\n",
        "  doc_ref.set({'algorithum':'yolo','version':'1','mode':'detection','url':'yolo'})\n",
        "else:\n",
        "  doc_ref= yolo_doc"
      ],
      "metadata": {
        "id": "7zvkgCE-1aln"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Yolo Leaves"
      ],
      "metadata": {
        "id": "4AofJ-we2IpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_ref_leaves=doc_ref.collection(\"Leaves\")"
      ],
      "metadata": {
        "id": "fje9VeIz17ff"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_doc_leave_basic=yolo_ref_leaves.document('basic')"
      ],
      "metadata": {
        "id": "7t6O-OvY2ST7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_doc_leave_basic.set({\n",
        "    'account':email,\n",
        "    'profile':profile,\n",
        "})"
      ],
      "metadata": {
        "id": "YY8REIa72l_V",
        "outputId": "e8a1ee5a-5713-40c0-fbf4-9662dc519958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1725862376\n",
              "  nanos: 280581000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intial_basic_col=yolo_doc_leave_basic.collection(\"Intial\")"
      ],
      "metadata": {
        "id": "mEp4A_LK4D8q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subfolders=os.listdir(Dataset_dir)"
      ],
      "metadata": {
        "id": "OsBsgPqP4Sd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_datasetCount=0\n",
        "names=[]"
      ],
      "metadata": {
        "id": "LvzoodhgG9db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sub in subfolders:\n",
        "  yaml_file=os.path.join(Dataset_dir,sub,'data.yaml')\n",
        "  sub_doc=intial_basic_col.document(sub)\n",
        "  sub_doc_col_util=sub_doc.collection('Util')\n",
        "  sub_doc_col_util_dataYaml=sub_doc_col_util.document('datYaml')\n",
        "  sub_doc_col_util_Dataset_readMe=sub_doc_col_util.document('readme_Dataset')\n",
        "  sub_doc_col_util_roboflow_readMe=sub_doc_col_util.document('readme_roboflow')\n",
        "  dataset_count=dictory_images_count(os.path.join(Dataset_dir,sub))\n",
        "  total_datasetCount=total_datasetCount+dataset_count['total_count']\n",
        "  sub_doc.set(dataset_count)\n",
        "  datasetLines,roboflowlines=[],[]\n",
        "  with open(os.path.join(Dataset_dir,sub,'README.dataset.txt'), \"r\") as file:\n",
        "    datasetLines = file.readlines()\n",
        "  sub_doc_col_util_Dataset_readMe.set({'dataset':datasetLines})\n",
        "  with open(os.path.join(Dataset_dir,sub,'README.roboflow.txt'), \"r\") as file:\n",
        "    roboflowlines = file.readlines()\n",
        "  sub_doc_col_util_roboflow_readMe.set({\n",
        "      'roboflow':roboflowlines\n",
        "  })\n",
        "  with open(yaml_file, 'r') as file:\n",
        "    yaml_content = yaml.safe_load(file)\n",
        "    names.extend(yaml_content['names'])\n",
        "    sub_doc_col_util_dataYaml.set(yaml_content)\n",
        "    sub_doc.update({'names':yaml_content['names'],'no_of_species':yaml_content['nc'],'roboflow':yaml_content['roboflow']})"
      ],
      "metadata": {
        "id": "Z2hvH-rc7V7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_doc_leave_basic.update({\n",
        "    'count':total_datasetCount,\n",
        "    'names':list(set(names))\n",
        "})"
      ],
      "metadata": {
        "id": "aYUw_32LHpwL",
        "outputId": "ab9925b4-ea06-43cf-b1b5-c5237c737fa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1725862570\n",
              "  nanos: 231251000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "from collections import defaultdict\n",
        "\n",
        "def load_class_names(yaml_path):\n",
        "    \"\"\"Load class names from data.yaml.\"\"\"\n",
        "    with open(yaml_path, 'r') as file:\n",
        "        data = yaml.safe_load(file)\n",
        "    return {i: value for i, value in enumerate(data['names'])}\n",
        "\n",
        "def map_files_to_classes(base_path, yaml_path):\n",
        "    \"\"\"Map number of files for each class.\"\"\"\n",
        "    class_names = load_class_names(yaml_path)\n",
        "\n",
        "    # Initialize data structures\n",
        "    class_files = defaultdict(lambda: {\n",
        "        'count': 0,\n",
        "        'files': []\n",
        "    })\n",
        "\n",
        "    # Paths to label files\n",
        "    label_paths = {\n",
        "        'train': os.path.join(base_path, 'train', 'labels'),\n",
        "        'test': os.path.join(base_path, 'test', 'labels'),\n",
        "        'valid': os.path.join(base_path, 'valid', 'labels')\n",
        "    }\n",
        "\n",
        "    # Process each label file\n",
        "    for dataset in ['train', 'test', 'valid']:\n",
        "        label_path = label_paths[dataset]\n",
        "        for filename in os.listdir(label_path):\n",
        "            if filename.endswith('.txt'):\n",
        "                image_file = filename.replace('.txt', '.jpg')  # Assuming images are .jpg\n",
        "                label_file = os.path.join(label_path, filename)\n",
        "\n",
        "                with open(label_file, 'r') as file:\n",
        "                    classes = set()\n",
        "                    for line in file:\n",
        "                        parts = line.strip().split()\n",
        "                        class_id = int(parts[0])\n",
        "                        classes.add(class_names.get(class_id, 'unknown'))\n",
        "\n",
        "                for cls in classes:\n",
        "                    class_files[cls]['count'] += 1\n",
        "                    class_files[cls]['files'].append({\n",
        "                        'imagefile': image_file,\n",
        "                        'annotationfile': filename,\n",
        "                        'classes': list(classes)\n",
        "                    })\n",
        "\n",
        "    return class_files\n",
        "\n",
        "# Example usage\n",
        "\n"
      ],
      "metadata": {
        "id": "y3wQYpztQxqN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path=Dataset_dir\n",
        "for folder in os.listdir(root_path):\n",
        "  base_path =os.path.join(root_path,folder)\n",
        "  yaml_path = os.path.join(base_path,'data.yaml')\n",
        "  class_files = map_files_to_classes(base_path, yaml_path)\n",
        "  sub_doc=intial_basic_col.document(folder)\n",
        "  sub_doc_collection=sub_doc.collection(\"Species\")\n",
        "  for cls, info in class_files.items():\n",
        "    doc=sub_doc_collection.document(cls)\n",
        "    doc.set({\n",
        "        'count':info['count'],\n",
        "        'file_info':info['files']\n",
        "    })"
      ],
      "metadata": {
        "id": "apSSl24jQ1cM",
        "outputId": "eeee4f4c-01b4-454b-dc9f-650c1bf3e4ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Dataset_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8f2271b20901>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroot_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataset_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0myaml_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mclass_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_files_to_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myaml_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for subfold in subfolders:\n",
        "  path=os.path.join(Dataset_dir,subfold)\n",
        "  doc=intial_basic_col.document(subfold)\n",
        "  species_col=doc.collection('Species')\n",
        "\n"
      ],
      "metadata": {
        "id": "mes6IbcDOrik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare"
      ],
      "metadata": {
        "id": "7vsPRolabQng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intial_prepare_col=yolo_doc_leave_basic.collection(\"Prepare\")"
      ],
      "metadata": {
        "id": "eyK2qrlVbXMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sub in subfolders:\n",
        "  yaml_file=os.path.join(Dataset_dir,sub,'data.yaml')\n",
        "  sub_doc=intial_prepare_col.document(sub)\n",
        "  sub_doc_col_util=sub_doc.collection('Util')\n",
        "  sub_doc_col_util_dataYaml=sub_doc_col_util.document('datYaml')\n",
        "  sub_doc_col_util_Dataset_readMe=sub_doc_col_util.document('readme_Dataset')\n",
        "  sub_doc_col_util_roboflow_readMe=sub_doc_col_util.document('readme_roboflow')\n",
        "  dataset_count=dictory_images_count(os.path.join(Dataset_dir,sub))\n",
        "  total_datasetCount=total_datasetCount+dataset_count['total_count']\n",
        "  sub_doc.set(dataset_count)\n",
        "  datasetLines,roboflowlines=[],[]\n",
        "  with open(os.path.join(Dataset_dir,sub,'README.dataset.txt'), \"r\") as file:\n",
        "    datasetLines = file.readlines()\n",
        "  sub_doc_col_util_Dataset_readMe.set({'dataset':datasetLines})\n",
        "  with open(os.path.join(Dataset_dir,sub,'README.roboflow.txt'), \"r\") as file:\n",
        "    roboflowlines = file.readlines()\n",
        "  sub_doc_col_util_roboflow_readMe.set({\n",
        "      'roboflow':roboflowlines\n",
        "  })\n",
        "  with open(yaml_file, 'r') as file:\n",
        "    yaml_content = yaml.safe_load(file)\n",
        "    names.extend(yaml_content['names'])\n",
        "    sub_doc_col_util_dataYaml.set(yaml_content)\n",
        "    sub_doc.update({'names':yaml_content['names'],'no_of_species':yaml_content['nc'],'roboflow':yaml_content['roboflow']})"
      ],
      "metadata": {
        "id": "aR2D8dMGbw0h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}