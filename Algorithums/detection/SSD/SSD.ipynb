{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZp2Cu8B1sfS"
      },
      "source": [
        "# Single Shot Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7V-TZxO1sfV"
      },
      "source": [
        "## Setup Collab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "polk0H7T1sfW"
      },
      "source": [
        "### Install nessary packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wWLb--d1sfX"
      },
      "source": [
        "#### torchvision install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6uOVd5a1sfX",
        "outputId": "54bf740c-5e05-4beb-b576-12edd46f82e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "! pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5-mNoQ-1sfZ"
      },
      "source": [
        "#### albumentations install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CspHpv9d1sfZ",
        "outputId": "661754c3-dea4-445e-fe2f-a37c811b5a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-1.4.11-py3-none-any.whl (165 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.3/165.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Collecting scikit-image>=0.21.0 (from albumentations)\n",
            "  Downloading scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.12.2)\n",
            "Collecting scikit-learn>=1.3.2 (from albumentations)\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.8.2)\n",
            "Collecting albucore>=0.0.11 (from albumentations)\n",
            "  Downloading albucore-0.0.12-py3-none-any.whl (8.4 kB)\n",
            "Collecting eval-type-backport (from albumentations)\n",
            "  Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from albucore>=0.0.11->albumentations) (2.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.20.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (9.4.0)\n",
            "Collecting imageio>=2.33 (from scikit-image>=0.21.0->albumentations)\n",
            "  Downloading imageio-2.34.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.7.2)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.2->albumentations) (3.5.0)\n",
            "Installing collected packages: imageio, eval-type-backport, scikit-learn, scikit-image, albucore, albumentations\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.31.6\n",
            "    Uninstalling imageio-2.31.6:\n",
            "      Successfully uninstalled imageio-2.31.6\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.3.1\n",
            "    Uninstalling albumentations-1.3.1:\n",
            "      Successfully uninstalled albumentations-1.3.1\n",
            "Successfully installed albucore-0.0.12 albumentations-1.4.11 eval-type-backport-0.2.0 imageio-2.34.2 scikit-image-0.24.0 scikit-learn-1.5.1\n"
          ]
        }
      ],
      "source": [
        "! pip install -U albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KkZg_LJ1sfZ"
      },
      "source": [
        "#### opencv-python-headless install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azpdt5yI1sfa",
        "outputId": "393ca930-9d5e-4b02-ec3e-04f85f47a132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0V125lg1sfa"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1sf9HtK1sfb"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY-iWCxZ1sfb"
      },
      "source": [
        "#### basic Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BhQAXxP71sfb"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "993rScCB1sfb"
      },
      "outputs": [],
      "source": [
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tGN1pelU1sfc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K6iWTFNF1sfc"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Google"
      ],
      "metadata": {
        "id": "aRNRYMt32VwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "2WZLGWPT2M0j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42tJRWlV1sfc"
      },
      "source": [
        "####  torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h7xvppDX1sfc"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XFP2yDNt1sfd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFqojGFb1sfd"
      },
      "source": [
        "#### torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rMhhaIzB1sfd"
      },
      "outputs": [],
      "source": [
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XLo45peA1sfd"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "262b9mZP1sfd"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP886p4T1sfe"
      },
      "source": [
        "#### Albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PPmwq9aw1sfe"
      },
      "outputs": [],
      "source": [
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xl1zzvTD1sfe"
      },
      "outputs": [],
      "source": [
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3onXm1_f1sfe"
      },
      "source": [
        "#### ElementTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lYBPzV_A1sfe"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect with Google"
      ],
      "metadata": {
        "id": "uqVpB4rm2dYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive') # drive activate for Use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NxI4cBi2k34",
        "outputId": "58ad559f-8754-46fc-c5f5-b52e703195e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Device"
      ],
      "metadata": {
        "id": "WncE0w3k4hQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
      ],
      "metadata": {
        "id": "RMJMT5xe4kNu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEwbPPky1sff"
      },
      "source": [
        "## Custom Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBgePrZq1sff"
      },
      "source": [
        "### Dataset Handle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzG_C96G1sff"
      },
      "source": [
        "#### Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vJFFVgbo1sff"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_dir, ann_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.ann_dir = ann_dir\n",
        "        self.transform = transform\n",
        "        self.imgs = list(sorted(os.listdir(img_dir)))\n",
        "        self.anns = list(sorted(os.listdir(ann_dir)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.imgs[idx])\n",
        "        ann_path = os.path.join(self.ann_dir, self.anns[idx])\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        tree = ET.parse(ann_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        for member in root.findall('object'):\n",
        "            labels.append(int(member.find('name').text))\n",
        "            bndbox = member.find('bndbox')\n",
        "            xmin = int(bndbox.find('xmin').text)\n",
        "            ymin = int(bndbox.find('ymin').text)\n",
        "            xmax = int(bndbox.find('xmax').text)\n",
        "            ymax = int(bndbox.find('ymax').text)\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        boxes = np.array(boxes)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=img, bboxes=boxes, labels=labels)\n",
        "            img = transformed['image']\n",
        "            boxes = transformed['bboxes']\n",
        "            labels = transformed['labels']\n",
        "\n",
        "        target = {}\n",
        "        target['boxes'] = torch.tensor(boxes, dtype=torch.float32)\n",
        "        target['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX9KJV0h1sfg"
      },
      "source": [
        "#### Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YZpv22KR1sfg"
      },
      "outputs": [],
      "source": [
        "transform = A.Compose([\n",
        "    A.Resize(300, 300),\n",
        "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6S71__o1sfg"
      },
      "source": [
        "#### collat function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eOHudtle1sfg"
      },
      "outputs": [],
      "source": [
        "collate_function=lambda x: tuple(zip(*x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDjnY4GB1sfg"
      },
      "source": [
        "#### model Evalutation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Mjw922Tf1sfh"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in val_loader:\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            val_loss += losses.item()\n",
        "\n",
        "            outputs = model(images)\n",
        "            for i, output in enumerate(outputs):\n",
        "                pred_boxes = output['boxes']\n",
        "                pred_labels = output['labels']\n",
        "                gt_boxes = targets[i]['boxes']\n",
        "                gt_labels = targets[i]['labels']\n",
        "\n",
        "                for box, label in zip(pred_boxes, pred_labels):\n",
        "                    if label in gt_labels:\n",
        "                        correct_predictions += 1\n",
        "                total_predictions += len(gt_labels)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olWgtvhg1sfh"
      },
      "source": [
        "#### model Traing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "n2YtIGP01sfm"
      },
      "outputs": [],
      "source": [
        "def modelTraing(model,num_epochs,train_loader,val_loader):\n",
        "    train_losses=[]\n",
        "    val_losses=[]\n",
        "    val_accuracies=[]\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for images, targets in train_loader:\n",
        "          images = list(image.to(device) for image in images)\n",
        "          targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "          loss_dict = model(images, targets)\n",
        "          losses = sum(loss for loss in loss_dict.values())\n",
        "          train_loss += losses.item()\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          losses.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        val_loss, val_accuracy = evaluate(model, val_loader, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "    return {\n",
        "        'val_loss':val_losses,\n",
        "        'val_accuracy':val_accuracies,\n",
        "        'train_losses':train_losses\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwfgRceN1sfn"
      },
      "source": [
        "#### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "v5CVbxgM1sfn"
      },
      "outputs": [],
      "source": [
        "def predict(model, image_path, device):\n",
        "    model.eval()\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_transformed = transform(image=img)['image']\n",
        "    img_transformed = img_transformed.to(device)\n",
        "    with torch.no_grad():\n",
        "        prediction = model([img_transformed])[0]\n",
        "\n",
        "    pred_boxes = prediction['boxes'].cpu().numpy().astype(np.int32)\n",
        "    pred_labels = prediction['labels'].cpu().numpy()\n",
        "\n",
        "    for i in range(len(pred_boxes)):\n",
        "        box = pred_boxes[i]\n",
        "        label = pred_labels[i]\n",
        "        cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
        "        cv2.putText(img, f'Class {label}', (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qcRS2541sfn"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-yKYHSt1sfn"
      },
      "source": [
        "### DataSet Dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVohRUyZ1sfn"
      },
      "source": [
        "####  Dataset dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksFeHeFM1sfo"
      },
      "source": [
        "##### train path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-T5j2oyE1sfo"
      },
      "outputs": [],
      "source": [
        "trainData_set_dir={\n",
        "    'image':'',\n",
        "    'annotate':''\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WXdousU1sfo"
      },
      "source": [
        "##### test path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GY0v8Q7G1sfo"
      },
      "outputs": [],
      "source": [
        "testData_set_dir={\n",
        "    'image':'',\n",
        "    'annotate':''\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xchyPJhg1sfo"
      },
      "source": [
        "##### Validation Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QuTP69QC1sfo"
      },
      "outputs": [],
      "source": [
        "valData_set_dir={\n",
        "    'image':'',\n",
        "    'annotate':''\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33OMWz7U1sfp"
      },
      "source": [
        "#### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptbiXT9y1sfp"
      },
      "source": [
        "##### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "HZvIxzfW1sfp",
        "outputId": "7b9be75f-8f25-4c63-9232-88b263988f50"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: ''",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-d519dcbb7ff0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainData_set_dir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mann_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainData_set_dir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-b45d4e241326>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_dir, ann_dir, transform)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
          ]
        }
      ],
      "source": [
        "train_dataset=CustomDataset(img_dir=trainData_set_dir['image'], ann_dir=trainData_set_dir['annotate'], transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Th8uUd01sfp"
      },
      "source": [
        "##### test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "154htlHN1sfp"
      },
      "outputs": [],
      "source": [
        "test_dataset=CustomDataset(img_dir=testData_set_dir['image'], ann_dir=testData_set_dir['annotate'], transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ASBrHuH1sfq"
      },
      "source": [
        "##### validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ebgVMDl1sfq"
      },
      "outputs": [],
      "source": [
        "val_dataset=CustomDataset(img_dir=valData_set_dir['image'], ann_dir=valData_set_dir['annotate'], transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEf_0m481sfq"
      },
      "source": [
        "#### Dataset Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UCuQ8rq1sfq"
      },
      "source": [
        "##### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoZnZDgS1sfr"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d7SVL6A1sfr"
      },
      "source": [
        "##### test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq1lbbvW1sfr"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=collate_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFD-imN61sfr"
      },
      "source": [
        "##### val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62_rcy6v1sfr"
      },
      "outputs": [],
      "source": [
        "validation_loader = DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfKb-v581sfs"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.ssd300_vgg16(pretrained=True)"
      ],
      "metadata": {
        "id": "xi3n7bh05XEl",
        "outputId": "d2299e66-d5af-403f-e1b7-4690a23758b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth\" to /root/.cache/torch/hub/checkpoints/ssd300_vgg16_coco-b556d3b4.pth\n",
            "100%|██████████| 136M/136M [00:01<00:00, 118MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eGianpwK1sfs"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_classes = 32  # Replace with the number of classes in your dataset, including background\n",
        "model.head.classification_head.num_classes = num_classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "SoIXCK081sfs",
        "outputId": "58a459f1-f1d0-46d2-c70a-166c947e5ad2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'SSDClassificationHead' object has no attribute 'cls_logits'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-1e00e69ea718>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SSDClassificationHead' object has no attribute 'cls_logits'"
          ]
        }
      ],
      "source": [
        "in_features = model.head.classification_head.cls_logits.in_channels\n",
        "out_channels = model.head.classification_head.num_classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJpoO2mN1sfs"
      },
      "outputs": [],
      "source": [
        "cls_logits = torch.nn.Conv2d(in_features, out_channels, kernel_size=3, padding=1)\n",
        "model.head.classification_head.cls_logits = cls_logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WluBhxun1sft"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
      ],
      "metadata": {
        "id": "HOqSqB4A40qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCOLZ0io1sft"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swAIL_rH1sft"
      },
      "source": [
        "num_epoches=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggm6w_T31sft"
      },
      "outputs": [],
      "source": [
        "accur_loss=modelTraing(model,num_epoches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b_Fixg01sft"
      },
      "source": [
        "#### visiblize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpb5L5vW1sft"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(num_epoches), accur_loss['train_losses'], label='Train Loss')\n",
        "plt.plot(range(num_epoches), accur_loss['val_losses'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Curve')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0aF_CE81sfu"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(num_epoches), accur_loss['val_accuracies'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_wkc1431sfu"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH9LjHXO1sfu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}