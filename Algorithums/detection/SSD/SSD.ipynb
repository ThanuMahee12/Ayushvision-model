{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThanuMahee12/ayush-vision/blob/ssd/Algorithums/detection/SSD/SSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZp2Cu8B1sfS"
      },
      "source": [
        "# Single Shot Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7V-TZxO1sfV"
      },
      "source": [
        "## Setup Collab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "polk0H7T1sfW"
      },
      "source": [
        "### Install nessary packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wWLb--d1sfX"
      },
      "source": [
        "#### torchvision install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6uOVd5a1sfX"
      },
      "outputs": [],
      "source": [
        "! pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5-mNoQ-1sfZ"
      },
      "source": [
        "#### albumentations install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CspHpv9d1sfZ"
      },
      "outputs": [],
      "source": [
        "! pip install -U albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KkZg_LJ1sfZ"
      },
      "source": [
        "#### opencv-python-headless install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Azpdt5yI1sfa"
      },
      "outputs": [],
      "source": [
        "! pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0V125lg1sfa"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1sf9HtK1sfb"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY-iWCxZ1sfb"
      },
      "source": [
        "#### basic Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhQAXxP71sfb"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "993rScCB1sfb"
      },
      "outputs": [],
      "source": [
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGN1pelU1sfc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6iWTFNF1sfc"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Google"
      ],
      "metadata": {
        "id": "aRNRYMt32VwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "2WZLGWPT2M0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42tJRWlV1sfc"
      },
      "source": [
        "####  torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7xvppDX1sfc"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFP2yDNt1sfd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFqojGFb1sfd"
      },
      "source": [
        "#### torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMhhaIzB1sfd"
      },
      "outputs": [],
      "source": [
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLo45peA1sfd"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "262b9mZP1sfd"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP886p4T1sfe"
      },
      "source": [
        "#### Albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPmwq9aw1sfe"
      },
      "outputs": [],
      "source": [
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl1zzvTD1sfe"
      },
      "outputs": [],
      "source": [
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3onXm1_f1sfe"
      },
      "source": [
        "#### ElementTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYBPzV_A1sfe"
      },
      "outputs": [],
      "source": [
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect with Google"
      ],
      "metadata": {
        "id": "uqVpB4rm2dYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive') # drive activate for Use"
      ],
      "metadata": {
        "id": "7NxI4cBi2k34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEwbPPky1sff"
      },
      "source": [
        "## Custom Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBgePrZq1sff"
      },
      "source": [
        "### Dataset Handle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzG_C96G1sff"
      },
      "source": [
        "#### Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJFFVgbo1sff"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_dir, ann_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.ann_dir = ann_dir\n",
        "        self.transform = transform\n",
        "        self.imgs = list(sorted(os.listdir(img_dir)))\n",
        "        self.anns = list(sorted(os.listdir(ann_dir)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.imgs[idx])\n",
        "        ann_path = os.path.join(self.ann_dir, self.anns[idx])\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        tree = ET.parse(ann_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        for member in root.findall('object'):\n",
        "            labels.append(int(member.find('name').text))\n",
        "            bndbox = member.find('bndbox')\n",
        "            xmin = int(bndbox.find('xmin').text)\n",
        "            ymin = int(bndbox.find('ymin').text)\n",
        "            xmax = int(bndbox.find('xmax').text)\n",
        "            ymax = int(bndbox.find('ymax').text)\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        boxes = np.array(boxes)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=img, bboxes=boxes, labels=labels)\n",
        "            img = transformed['image']\n",
        "            boxes = transformed['bboxes']\n",
        "            labels = transformed['labels']\n",
        "\n",
        "        target = {}\n",
        "        target['boxes'] = torch.tensor(boxes, dtype=torch.float32)\n",
        "        target['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX9KJV0h1sfg"
      },
      "source": [
        "#### Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZpv22KR1sfg"
      },
      "outputs": [],
      "source": [
        "transform = A.Compose([\n",
        "    A.Resize(300, 300),\n",
        "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
        "    ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6S71__o1sfg"
      },
      "source": [
        "#### collat function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOHudtle1sfg"
      },
      "outputs": [],
      "source": [
        "collate_function=lambda x: tuple(zip(*x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDjnY4GB1sfg"
      },
      "source": [
        "#### model Evalutation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mjw922Tf1sfh"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in val_loader:\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            val_loss += losses.item()\n",
        "\n",
        "            outputs = model(images)\n",
        "            for i, output in enumerate(outputs):\n",
        "                pred_boxes = output['boxes']\n",
        "                pred_labels = output['labels']\n",
        "                gt_boxes = targets[i]['boxes']\n",
        "                gt_labels = targets[i]['labels']\n",
        "\n",
        "                for box, label in zip(pred_boxes, pred_labels):\n",
        "                    if label in gt_labels:\n",
        "                        correct_predictions += 1\n",
        "                total_predictions += len(gt_labels)\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olWgtvhg1sfh"
      },
      "source": [
        "#### model Traing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2YtIGP01sfm"
      },
      "outputs": [],
      "source": [
        "def modelTraing(model,num_epochs):\n",
        "    train_losses=[]\n",
        "    val_losses=[]\n",
        "    val_accuracies=[]\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for images, targets in train_loader:\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        train_loss += losses.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        val_loss, val_accuracy = evaluate(model, val_loader, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "    return {\n",
        "        'val_loss':val_losses,\n",
        "        'val_accuracy':val_accuracies,\n",
        "        'train_losses':train_losses\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwfgRceN1sfn"
      },
      "source": [
        "#### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5CVbxgM1sfn"
      },
      "outputs": [],
      "source": [
        "def predict(model, image_path, device):\n",
        "    model.eval()\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_transformed = transform(image=img)['image']\n",
        "    img_transformed = img_transformed.to(device)\n",
        "    with torch.no_grad():\n",
        "        prediction = model([img_transformed])[0]\n",
        "\n",
        "    pred_boxes = prediction['boxes'].cpu().numpy().astype(np.int32)\n",
        "    pred_labels = prediction['labels'].cpu().numpy()\n",
        "\n",
        "    for i in range(len(pred_boxes)):\n",
        "        box = pred_boxes[i]\n",
        "        label = pred_labels[i]\n",
        "        cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
        "        cv2.putText(img, f'Class {label}', (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qcRS2541sfn"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-yKYHSt1sfn"
      },
      "source": [
        "### DataSet Dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVohRUyZ1sfn"
      },
      "source": [
        "####  Dataset dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksFeHeFM1sfo"
      },
      "source": [
        "##### train path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T5j2oyE1sfo"
      },
      "outputs": [],
      "source": [
        "trainData_set_dir={\n",
        "    'image':'',\n",
        "    'annotate':''\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WXdousU1sfo"
      },
      "source": [
        "##### test path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY0v8Q7G1sfo"
      },
      "outputs": [],
      "source": [
        "testData_set_dir={\n",
        "    'image':'',\n",
        "    'annotate':''\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xchyPJhg1sfo"
      },
      "source": [
        "##### Validation Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuTP69QC1sfo"
      },
      "outputs": [],
      "source": [
        "valData_set_dir={\n",
        "    'image':'',\n",
        "    'annotate':''\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33OMWz7U1sfp"
      },
      "source": [
        "#### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptbiXT9y1sfp"
      },
      "source": [
        "##### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZvIxzfW1sfp"
      },
      "outputs": [],
      "source": [
        "train_dataset=CustomDataset(img_dir=trainData_set_dir['image'], ann_dir=trainData_set_dir['annotate'], transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Th8uUd01sfp"
      },
      "source": [
        "##### test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "154htlHN1sfp"
      },
      "outputs": [],
      "source": [
        "test_dataset=CustomDataset(img_dir=testData_set_dir['image'], ann_dir=testData_set_dir['annotate'], transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ASBrHuH1sfq"
      },
      "source": [
        "##### validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ebgVMDl1sfq"
      },
      "outputs": [],
      "source": [
        "val_dataset=CustomDataset(img_dir=valData_set_dir['image'], ann_dir=valData_set_dir['annotate'], transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEf_0m481sfq"
      },
      "source": [
        "#### Dataset Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UCuQ8rq1sfq"
      },
      "source": [
        "##### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoZnZDgS1sfr"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d7SVL6A1sfr"
      },
      "source": [
        "##### test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq1lbbvW1sfr"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=collate_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFD-imN61sfr"
      },
      "source": [
        "##### val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62_rcy6v1sfr"
      },
      "outputs": [],
      "source": [
        "validation_loader = DataLoader(val_dataset, batch_size=4, shuffle=True, collate_fn=collate_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfKb-v581sfs"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ECskgyV1sfs"
      },
      "source": [
        "model = torchvision.models.detection.ssd300_vgg16(pretrained=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGianpwK1sfs"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_classes = 32  # Replace with the number of classes in your dataset, including background\n",
        "model.head.classification_head.num_classes = num_classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoIXCK081sfs"
      },
      "outputs": [],
      "source": [
        "in_features = model.head.classification_head.cls_logits.in_channels\n",
        "out_channels = model.head.classification_head.num_classes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJpoO2mN1sfs"
      },
      "outputs": [],
      "source": [
        "cls_logits = torch.nn.Conv2d(in_features, out_channels, kernel_size=3, padding=1)\n",
        "model.head.classification_head.cls_logits = cls_logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WluBhxun1sft"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCOLZ0io1sft"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swAIL_rH1sft"
      },
      "source": [
        "num_epoches=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggm6w_T31sft"
      },
      "outputs": [],
      "source": [
        "accur_loss=modelTraing(model,num_epoches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b_Fixg01sft"
      },
      "source": [
        "#### visiblize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpb5L5vW1sft"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(num_epoches), accur_loss['train_losses'], label='Train Loss')\n",
        "plt.plot(range(num_epoches), accur_loss['val_losses'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Curve')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0aF_CE81sfu"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(num_epoches), accur_loss['val_accuracies'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_wkc1431sfu"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH9LjHXO1sfu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}