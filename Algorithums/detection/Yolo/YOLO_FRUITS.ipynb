{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThanuMahee12/ayush-vision/blob/yolo/Algorithums/detection/Yolo/YOLO_FRUITS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWi18aj0n7HU"
      },
      "source": [
        "# YOLO FRUITS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CM_KjiNtVB7"
      },
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r-r4NsGoIwe",
        "outputId": "04faef8a-b28a-4de5-d9f7-917ee4b10035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZKSwn8-clJNR"
      },
      "outputs": [],
      "source": [
        "basicdata={'account':'rainorobot334567@gmail.com','user':\"Thanush\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0Q4dWFHbYdR",
        "outputId": "47c925e5-d057-4d3b-c316-bfb1e3f5b3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating locales (this might take a while)...\n",
            "  en_US.UTF-8... done\n",
            "Generation complete.\n"
          ]
        }
      ],
      "source": [
        "! locale-gen en_US.UTF-8\n",
        "! export LC_ALL=en_US.UTF-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4jrfd8WtYpd"
      },
      "source": [
        "## Intallations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRKGcqEKhzzt"
      },
      "outputs": [],
      "source": [
        "!pip install firebase-admin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx51cd0goqWi",
        "outputId": "b1c732ae-7b5f-4a4e-e73a-747d9d62b212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.93-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.6-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.93-py3-none-any.whl (871 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m871.6/871.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.6-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.2.93 ultralytics-thop-2.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "firebase_count=1"
      ],
      "metadata": {
        "id": "iczN829k3l3d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF-FeFKVtc0j"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LA6879REh_Yu"
      },
      "outputs": [],
      "source": [
        "import firebase_admin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TxfkdTzEiEie"
      },
      "outputs": [],
      "source": [
        "from firebase_admin import credentials,storage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z1wqn3xWiGgv"
      },
      "outputs": [],
      "source": [
        "from firebase_admin import firestore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vWoaQzKEn7He"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2vAitzxpoa7a"
      },
      "outputs": [],
      "source": [
        "from datetime import date,datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QXBrUhRTn7Hg"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3H26Ktufn7Hh"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YX-4QEzwn7Hi"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VPtnbmKmpo6w"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3zftmIrTuI99"
      },
      "outputs": [],
      "source": [
        "import yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "xwwPh4JmKh0n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "46i8epZ0K-Mm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLe9eLGetyX_"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "c_qNgMdot0QK"
      },
      "outputs": [],
      "source": [
        "epochs=50\n",
        "imageSize=640\n",
        "optimizer='Adam'\n",
        "dropout=0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPNvfYoiKmz8"
      },
      "source": [
        "### Dirctory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hrtvf7FqKZzj"
      },
      "outputs": [],
      "source": [
        "work_dirctory_root=\"/content/drive/MyDrive/AyushVision/yolo8\"\n",
        "work_dirctory_training=f\"{work_dirctory_root}/training\"\n",
        "firebase_key=\"/content/drive/MyDrive/AyushVision/ServiceKey.json\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NWkZ6kdWl9Tc"
      },
      "outputs": [],
      "source": [
        "today_work_dirctory=f\"{work_dirctory_training}/{date.today().strftime('%d_%m_%Y')}/{date.today().strftime('%H%M%s')}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VCixGiXvmBWf"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(work_dirctory_training):\n",
        "  os.makedirs(work_dirctory_training,exist_ok=True)\n",
        "if not os.path.exists(today_work_dirctory):\n",
        "  os.makedirs(today_work_dirctory,exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iAbj-AXXmEo7"
      },
      "outputs": [],
      "source": [
        "data=f\"{work_dirctory_root}/dataset/final/data.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=\"\""
      ],
      "metadata": {
        "id": "0VX88m3Aer9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "J77aImwXtlPV"
      },
      "outputs": [],
      "source": [
        "project=f\"{today_work_dirctory}/fruits/runs\"\n",
        "name=f'train{epochs}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV9QP9llluYJ"
      },
      "source": [
        "## Firebase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RpsSJqZBiPpe"
      },
      "outputs": [],
      "source": [
        "\n",
        "if firebase_count==1:\n",
        "  cred = credentials.Certificate(firebase_key)\n",
        "  firebase_admin.initialize_app(cred,{\n",
        "      'storageBucket': 'ayush-vision-asw4gh.appspot.com'\n",
        "  })\n",
        "firebase_count=firebase_count+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UlsbRiTTj259"
      },
      "outputs": [],
      "source": [
        "db = firestore.client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1MqZJtEzv4eF"
      },
      "outputs": [],
      "source": [
        "bucket = storage.bucket()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "FjHEnE_7qSNN"
      },
      "outputs": [],
      "source": [
        "yolo_ref = db.collection(\"training1\").document('yolo')\n",
        "doc = yolo_ref.get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mivbo7JFl00U"
      },
      "outputs": [],
      "source": [
        "if not doc.exists:\n",
        "  doc_ref= db.collection(\"training1\").document('yolo')\n",
        "  doc_ref.set({'algorithum':'yolo','version':'V8','mode':'detection','url':'ultralytics'})\n",
        "else:\n",
        "  doc_ref= yolo_ref"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtFuKd42KznG"
      },
      "source": [
        "### Roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AapMM59Xn7Hj"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_id=f'{datetime.now().strftime(f\"%Y%m%d%H%s\")}_{epochs}'"
      ],
      "metadata": {
        "id": "CWoSck3FnI6E"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_id=\"20240914031726285191_50\""
      ],
      "metadata": {
        "id": "ErvXMgGIbyOW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storageLocation=f'training/yolo/fruit/{document_id}'"
      ],
      "metadata": {
        "id": "lLE23GP5nSgx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Mwg3H-G3orDr"
      },
      "outputs": [],
      "source": [
        "today_ref=doc_ref.collection(\"Fruit\").document(document_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7UvmNAyIreO8"
      },
      "outputs": [],
      "source": [
        "basicdata['imageSize']=imageSize\n",
        "basicdata['project']=project\n",
        "basicdata['name']=name\n",
        "basicdata['training_date']=datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
        "basicdata['filename']='YOLO_FRUITS'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-YZRg5JWuAEM"
      },
      "outputs": [],
      "source": [
        "with open(data, 'r') as file:\n",
        "    yaml_content = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PY06W962uaMn"
      },
      "outputs": [],
      "source": [
        "basicdata['names']=yaml_content['names']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UafSx86dkAcs",
        "outputId": "6e4dcfe4-afa1-423a-e7db-cc464419a170"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1726285204\n",
              "  nanos: 266307000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "today_ref.set(basicdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTFQPVebn7Hk",
        "outputId": "6a553797-d5c1-4d9b-a9c0-3a89cfa5c735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 113MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 355/355 items from pretrained weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "yolo_model = YOLO('yolov8n.yaml').load('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EMUXQQAn7Hm"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyofPiscn7Hn",
        "outputId": "031381d3-71c4-47cf-890b-6f8bc0b37825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.93 🚀 Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/drive/MyDrive/AyushVision/yolo8/dataset/final/data.yaml, epochs=50, time=None, patience=10, batch=16, imgsz=640, save=True, save_period=10, cache=False, device=None, workers=8, project=/content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs, name=train50, exist_ok=True, pretrained=yolov8n.pt, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.5, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.007, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs/train50\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 24.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=32\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    757552  ultralytics.nn.modules.head.Detect           [32, [64, 128, 256]]          \n",
            "YOLOv8n summary: 225 layers, 3,017,088 parameters, 3,017,072 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs/train50', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/AyushVision/yolo8/dataset/final/train/labels... 3773 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3773/3773 [26:56<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/AyushVision/yolo8/dataset/final/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.15 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/AyushVision/yolo8/dataset/final/valid/labels... 360 images, 0 backgrounds, 0 corrupt: 100%|██████████| 360/360 [02:38<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/AyushVision/yolo8/dataset/final/valid/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs/train50/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.007), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs/train50\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50       2.3G      1.822      2.994      1.946         29        640: 100%|██████████| 236/236 [01:40<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.339     0.0173    0.00339    0.00117\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      2.23G      1.945      2.859      2.018         23        640: 100%|██████████| 236/236 [01:32<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.256      0.155     0.0807      0.042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      2.17G      1.903      2.794      1.994         34        640: 100%|██████████| 236/236 [01:40<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.345     0.0588     0.0396     0.0167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      2.23G      1.859       2.68      1.947         28        640: 100%|██████████| 236/236 [01:50<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.512      0.093     0.0517     0.0204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      2.23G      1.816      2.613      1.903         31        640: 100%|██████████| 236/236 [01:49<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.241      0.312       0.24      0.117\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      2.23G      1.796      2.574      1.878         30        640: 100%|██████████| 236/236 [01:36<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.195      0.132      0.106     0.0378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      2.19G       1.77      2.463      1.857         31        640: 100%|██████████| 236/236 [01:32<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456       0.29      0.244      0.238      0.103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      2.17G      1.761      2.435      1.856         28        640: 100%|██████████| 236/236 [01:35<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.602      0.194      0.229     0.0891\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      2.17G      1.753      2.437      1.837         28        640: 100%|██████████| 236/236 [01:35<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:07<00:00,  1.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.229      0.342      0.269      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      2.17G      1.731      2.392      1.807         33        640: 100%|██████████| 236/236 [01:35<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456       0.41       0.36      0.286      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      2.23G      1.751      2.356      1.831         39        640: 100%|██████████| 236/236 [01:31<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.362      0.366      0.335      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      2.23G      1.745      2.355      1.838         23        640: 100%|██████████| 236/236 [01:33<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.472      0.419      0.373      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      2.19G      1.717      2.287      1.806         27        640: 100%|██████████| 236/236 [01:43<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.422      0.378       0.33      0.162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      2.19G      1.716      2.264      1.792         24        640: 100%|██████████| 236/236 [01:53<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.306      0.387      0.316      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      2.23G      1.693      2.238       1.78         41        640: 100%|██████████| 236/236 [01:36<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456       0.38      0.484      0.448      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      2.23G      1.667      2.188      1.747         24        640: 100%|██████████| 236/236 [01:35<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.411      0.402       0.35      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      2.23G      1.677      2.202      1.763         23        640: 100%|██████████| 236/236 [01:34<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.471       0.47      0.412      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      2.23G      1.644      2.191      1.758         33        640: 100%|██████████| 236/236 [01:36<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.231      0.336      0.243      0.122\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      2.23G      1.664      2.124      1.754         34        640: 100%|██████████| 236/236 [01:35<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:07<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.467      0.399      0.424      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      2.23G      1.654      2.126      1.736         34        640: 100%|██████████| 236/236 [01:33<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.338      0.461      0.415      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      2.23G      1.643      2.089      1.746         33        640: 100%|██████████| 236/236 [01:36<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.539      0.505      0.524      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      2.23G      1.643      2.062      1.742         34        640: 100%|██████████| 236/236 [01:35<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.448      0.475      0.455      0.228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      2.23G      1.654      2.061      1.748         27        640: 100%|██████████| 236/236 [01:36<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.427      0.433      0.413      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      2.23G      1.601      1.992      1.703         41        640: 100%|██████████| 236/236 [01:31<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.301      0.416       0.34      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      2.17G      1.602       1.98      1.706         28        640: 100%|██████████| 236/236 [01:34<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456       0.64      0.487      0.558      0.317\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      2.17G        1.6      1.983      1.698         35        640: 100%|██████████| 236/236 [01:34<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.466      0.489      0.503      0.272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      2.23G      1.587      1.922      1.683         37        640: 100%|██████████| 236/236 [01:35<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.688      0.472      0.567      0.304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50      2.23G      1.577      1.905      1.691         30        640: 100%|██████████| 236/236 [01:30<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.508      0.532      0.532      0.288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      2.23G      1.546      1.828      1.654         31        640: 100%|██████████| 236/236 [01:33<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:07<00:00,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.602      0.591      0.626      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      2.24G      1.555      1.805      1.664         30        640: 100%|██████████| 236/236 [01:36<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.641      0.467      0.515      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      2.23G      1.554      1.825      1.657         31        640: 100%|██████████| 236/236 [01:34<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:07<00:00,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.582      0.615      0.625      0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      2.24G      1.526      1.793      1.644         30        640: 100%|██████████| 236/236 [01:32<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.554      0.653      0.636      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      2.23G       1.51      1.743       1.62         29        640: 100%|██████████| 236/236 [01:37<00:00,  2.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456       0.58      0.566       0.59      0.328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      2.17G      1.507      1.741      1.628         23        640: 100%|██████████| 236/236 [01:35<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.585      0.555      0.603      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      2.19G      1.494      1.707      1.621         27        640: 100%|██████████| 236/236 [01:36<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.605      0.649      0.674      0.394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      2.23G      1.489      1.671      1.613         37        640: 100%|██████████| 236/236 [01:35<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.649      0.649      0.696      0.404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      2.23G      1.467      1.619      1.592         39        640: 100%|██████████| 236/236 [01:37<00:00,  2.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.804      0.634      0.727      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      2.17G      1.458        1.6      1.588         31        640: 100%|██████████| 236/236 [01:39<00:00,  2.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.793      0.647      0.739      0.434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      2.23G      1.449      1.591      1.583         23        640: 100%|██████████| 236/236 [01:33<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:07<00:00,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.674      0.712      0.745      0.436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      2.23G      1.426      1.556      1.564         33        640: 100%|██████████| 236/236 [01:35<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.705      0.649      0.721      0.433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      2.21G      1.399      1.442      1.662         13        640: 100%|██████████| 236/236 [01:35<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.724      0.703      0.744      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      2.17G      1.377      1.357      1.635         22        640: 100%|██████████| 236/236 [01:29<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.693      0.722      0.762      0.468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      2.17G      1.337      1.303       1.61         19        640: 100%|██████████| 236/236 [01:31<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.745       0.73      0.772      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      2.23G      1.329      1.256      1.604         14        640: 100%|██████████| 236/236 [01:33<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.774      0.716      0.782      0.491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      2.17G      1.314       1.23      1.586         17        640: 100%|██████████| 236/236 [01:33<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:07<00:00,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.791      0.722      0.785      0.487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      2.17G      1.309      1.206      1.577         15        640: 100%|██████████| 236/236 [01:28<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.762      0.717       0.78      0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      2.17G      1.289      1.179       1.56         16        640: 100%|██████████| 236/236 [01:33<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.732      0.728      0.782      0.498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      2.19G      1.285      1.165      1.566         19        640: 100%|██████████| 236/236 [01:33<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.755      0.737      0.796      0.501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50      2.17G      1.279      1.152      1.551         15        640: 100%|██████████| 236/236 [01:30<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.781      0.734      0.795      0.501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      2.17G      1.273       1.15       1.55         17        640: 100%|██████████| 236/236 [01:33<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.744      0.743      0.796      0.503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 1.427 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs/train50/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from /content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs/train50/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating /content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs/train50/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.93 🚀 Python-3.10.12 torch-2.4.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3,011,888 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:10<00:00,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        456      0.746      0.744      0.795      0.503\n",
            "                  lime         40         45      0.784      0.889      0.921      0.721\n",
            "   Calotropis_gigantea         40         42      0.792      0.833      0.894      0.685\n",
            "                Caster         40         56      0.718      0.446      0.517      0.297\n",
            "         Indian_Mallow         40         49       0.73      0.716      0.775      0.491\n",
            "             Ivy_gourd         40         48      0.767      0.896      0.911      0.534\n",
            "           Long_pepper         40         48      0.679      0.926      0.909      0.495\n",
            "         Pedaliummurex         40         61      0.721      0.764      0.801      0.532\n",
            "      Redpea_egg_plant         41         63      0.684      0.275       0.47      0.191\n",
            "        Ringworm_plant         40         44      0.839      0.951      0.961      0.583\n",
            "Speed: 0.5ms preprocess, 3.4ms inference, 0.0ms loss, 7.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs/train50\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "results = yolo_model.train(\n",
        "    data=data,\n",
        "    name=name,\n",
        "    epochs=epochs,\n",
        "    imgsz=imageSize,\n",
        "    project=project,\n",
        "    optimizer=optimizer,\n",
        "    plots=True,\n",
        "    dropout=dropout,\n",
        "    patience=10,\n",
        "    save=True,\n",
        "    save_period=10,\n",
        "    exist_ok=True,\n",
        "    verbose=True,\n",
        "    cos_lr=True,\n",
        "    weight_decay=0.007,\n",
        "    val=True\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args_yaml=f'{project}/{name}/args.yaml'"
      ],
      "metadata": {
        "id": "MdBQmfy28ayr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultcsv=f'{project}/{name}/results.csv'"
      ],
      "metadata": {
        "id": "H8adM3bo8b3r"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(resultcsv, mode='r') as file:\n",
        "     csv_reader = csv.DictReader(file)\n",
        "     data_dict = [row for row in csv_reader]"
      ],
      "metadata": {
        "id": "UFuXpXk-8h5S"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(args_yaml, 'r') as file:\n",
        "    yaml_content = yaml.safe_load(file)"
      ],
      "metadata": {
        "id": "w2dt5YSU8lxH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "j0b7pQMdwiee"
      },
      "outputs": [],
      "source": [
        "today_training_colref=today_ref.collection('Train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "today_training_ref=today_training_colref.document('args')"
      ],
      "metadata": {
        "id": "h93Bdy0883l4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today_training_ref.set(yaml_content)"
      ],
      "metadata": {
        "id": "1fxk0yTh84zE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f180e0-9de3-488d-8150-d425524dd8dc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1726292249\n",
              "  nanos: 707184000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "todayresultref=today_training_colref.document('results')"
      ],
      "metadata": {
        "id": "e_cpWpnJ8_DT"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "todayresultref.set({'results':data_dict})"
      ],
      "metadata": {
        "id": "_O3rQ8Oe9DPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282338fc-6839-4ce1-9351-5b7ed8eefa37"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1726292249\n",
              "  nanos: 974884000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "g-BcnpaezP3a"
      },
      "outputs": [],
      "source": [
        "trainfiles={}\n",
        "wights={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "jhuDVlf7xyNL"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir(f\"{project}/{name}\"):\n",
        "  if os.path.isfile(f\"{project}/{name}/{file}\"):\n",
        "    blob = bucket.blob(f\"{storageLocation}/train/{file}\")\n",
        "    blob.upload_from_filename(f\"{project}/{name}/{file}\")\n",
        "    blob.make_public()\n",
        "    trainfiles[os.path.splitext(file)[0]]=blob.public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "qbmOsJHgNmoU"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir(f\"{project}/{name}/weights\"):\n",
        "  if os.path.isfile(f\"{project}/{name}/weights/{file}\"):\n",
        "    blob = bucket.blob(f\"{storageLocation}/train/weights/{file}\")\n",
        "    blob.upload_from_filename(f\"{project}/{name}/weights/{file}\")\n",
        "    blob.make_public()\n",
        "    wights[os.path.splitext(file)[0]]=blob.public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "rMcQNIy10MUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2cd791-ba35-4922-9230-c45a57814521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1726292305\n",
              "  nanos: 446817000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "today_training_files=today_training_colref.document('files')\n",
        "today_training_files.set(trainfiles)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "today_weights_files=today_training_colref.document('weights')\n",
        "today_weights_files.set(wights)"
      ],
      "metadata": {
        "id": "mYZPqIsd9ju5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5636da-5abf-4db5-b452-82ad8523f5ba"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1726292306\n",
              "  nanos: 82708000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vebaeyvan7Ho"
      },
      "source": [
        "#### Validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name='train50'"
      ],
      "metadata": {
        "id": "Zzb_FtR3clS1"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project=\"/content/drive/MyDrive/AyushVision/yolo8/training/14_09_2024/00001726272000/fruits/runs\""
      ],
      "metadata": {
        "id": "UM0BxbjPYBLU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "-9orCdN0n7Ho"
      },
      "outputs": [],
      "source": [
        "model_train_path=f'{project}/{name}/weights/best.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "eGWISZx7n7Hp"
      },
      "outputs": [],
      "source": [
        "model = YOLO(model_train_path)  # load a custom trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "AXl1m-taeNDN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4857fde-1fcd-4dce-be5a-a13aaeb7316f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'\u001b[31m\u001b[1mexist\u001b[0m' is not a valid YOLO argument. Similar arguments are i.e. ['exist_ok=False'].\n\n    Arguments received: ['yolo', '-f', '/root/.local/share/jupyter/runtime/kernel-9467f8e9-cb0e-40ba-8b89-7bf4f75aca2e.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'segment', 'classify', 'pose', 'obb', 'detect'}\n                MODE (required) is one of {'track', 'predict', 'export', 'train', 'benchmark', 'val'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n        yolo explorer data=data.yaml model=yolov8n.pt\n    \n    6. Streamlit real-time webcam inference GUI\n        yolo streamlit-predict\n        \n    7. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-52-31375408fbf4>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<cell line: 1>\u001b[0m\n    metrics = model.val(exist=True,save_json=True,plots=True,project=project,name=f'val{epochs}')  # no arguments needed, dataset and settings remembered\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\"\u001b[0m, line \u001b[1;32m647\u001b[0m, in \u001b[1;35mval\u001b[0m\n    validator = (validator or self._smart_load(\"validator\"))(args=args, _callbacks=self.callbacks)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/val.py\"\u001b[0m, line \u001b[1;32m33\u001b[0m, in \u001b[1;35m__init__\u001b[0m\n    super().__init__(dataloader, save_dir, pbar, args, _callbacks)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/validator.py\"\u001b[0m, line \u001b[1;32m79\u001b[0m, in \u001b[1;35m__init__\u001b[0m\n    self.args = get_cfg(overrides=args)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\"\u001b[0m, line \u001b[1;32m255\u001b[0m, in \u001b[1;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\n",
            "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\"\u001b[0;36m, line \u001b[0;32m440\u001b[0;36m, in \u001b[0;35mcheck_dict_alignment\u001b[0;36m\u001b[0m\n\u001b[0;31m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '\u001b[31m\u001b[1mexist\u001b[0m' is not a valid YOLO argument. Similar arguments are i.e. ['exist_ok=False'].\n\n    Arguments received: ['yolo', '-f', '/root/.local/share/jupyter/runtime/kernel-9467f8e9-cb0e-40ba-8b89-7bf4f75aca2e.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'segment', 'classify', 'pose', 'obb', 'detect'}\n                MODE (required) is one of {'track', 'predict', 'export', 'train', 'benchmark', 'val'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    5. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n        yolo explorer data=data.yaml model=yolov8n.pt\n    \n    6. Streamlit real-time webcam inference GUI\n        yolo streamlit-predict\n        \n    7. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
          ]
        }
      ],
      "source": [
        "metrics = model.val(exist=True,save_json=True,plots=True,project=project,name=f'val{epochs}')  # no arguments needed, dataset and settings remembered"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "storageLocation=f'training/yolo/fruit/{document_id}'"
      ],
      "metadata": {
        "id": "LmqCJ6PCaKJ1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "q9FLMqVSzVDo"
      },
      "outputs": [],
      "source": [
        "val_today_col=today_ref.collection('Val')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predication_file=f'{project}/val{epochs}/predictions.json'"
      ],
      "metadata": {
        "id": "Ue99I-4m9_Hp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(predication_file, 'r') as file:\n",
        "    data_dict = json.load(file)"
      ],
      "metadata": {
        "id": "LnkXYv6f-DpZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_today_ref_files=val_today_col.document('files')"
      ],
      "metadata": {
        "id": "N9DvT2u_-FFB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "zUlTjrFB0JtF"
      },
      "outputs": [],
      "source": [
        "valfiles={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "f5kMLdoCTg9l"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir(f\"{project}/val{epochs}\"):\n",
        "  if os.path.isfile(f\"{project}/val{epochs}/{file}\"):\n",
        "    blob = bucket.blob(f\"{storageLocation}/val/{file}\")\n",
        "    blob.upload_from_filename(f\"{project}/val{epochs}/{file}\")\n",
        "    blob.make_public()\n",
        "    valfiles[os.path.splitext(file)[0]]=blob.public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "P5xtzL5GUB_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8877f259-1100-4539-ee36-20f370973c7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "update_time {\n",
              "  seconds: 1726299018\n",
              "  nanos: 49489000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "val_today_ref_files.set(valfiles)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_today_ref_metrics=val_today_col.document('metrics')"
      ],
      "metadata": {
        "id": "rm27eewN-neO"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_today_ref_metrics.set({\n",
        "    'confusion_matrix':{\n",
        "        'conf':metrics.confusion_matrix.conf\n",
        "    },\n",
        "    'maps':np.array(metrics.maps).tolist(),\n",
        "    'fitness':metrics.fitness,\n",
        "'results_dict':metrics.results_dict,\n",
        "    'speed':metrics.speed,\n",
        "    'box':{\n",
        "        'map':metrics.box.map,\n",
        "        'maps':np.array(metrics.box.maps).tolist(),\n",
        "        'map50':metrics.box.map50,\n",
        "        'map75':metrics.box.map75,\n",
        "        'mp':metrics.box.mp,\n",
        "'mr':metrics.box.mr,\n",
        "        'nc':metrics.box.nc,\n",
        "        'p':np.array(metrics.box.p).tolist(),\n",
        "        'r':np.array(metrics.box.r).tolist(),\n",
        "        'ap':np.array(metrics.box.ap).tolist(),\n",
        "        'ap50':np.array(metrics.box.ap50).tolist(),\n",
        "        'ap_class_index':np.array(metrics.box.ap_class_index).tolist(),\n",
        "        }\n",
        "})"
      ],
      "metadata": {
        "id": "P0j1ffJG-r-p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "c25e44aa-507b-4e62-c48e-93dc87bb116f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'metrics' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-12e9f62f8b22>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m val_today_ref_metrics.set({\n\u001b[1;32m      2\u001b[0m     'confusion_matrix':{\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m'conf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     },\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'maps'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8B6V3_wwohd"
      },
      "outputs": [],
      "source": [
        "metrics.box.map50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN0NsU2kwsYW"
      },
      "outputs": [],
      "source": [
        "metrics.box.map75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaONZry0wx04"
      },
      "outputs": [],
      "source": [
        "metrics.box.maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkbwnnv_n7Hp"
      },
      "source": [
        "#### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAQcdN7Mn7Hp"
      },
      "outputs": [],
      "source": [
        "results=model.predict(source=f'{work_dirctory_root}/dataset/final/test/images',save=True,save_txt=True,save_conf=True,save_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.show()"
      ],
      "metadata": {
        "id": "XGbAX39Rv47f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(f'{project}/predict'):\n",
        "  os.makedirs(f'{project}/predict')"
      ],
      "metadata": {
        "id": "8Bzhhf02vzSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming results[0].save_dir and project are defined\n",
        "image_files = [f for f in os.listdir(results[0].save_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
        "\n",
        "def save_predictions(images_per_row=5, max_images=50):\n",
        "    # Split the images into chunks of 50\n",
        "    for count, i in enumerate(range(0, len(image_files), max_images)):\n",
        "        image_files_subset = image_files[i:i + max_images]\n",
        "\n",
        "        # Calculate the number of rows needed\n",
        "        n_rows = len(image_files_subset) // images_per_row + int(len(image_files_subset) % images_per_row > 0)\n",
        "\n",
        "        # Create a figure with the necessary number of subplots\n",
        "        fig, axs = plt.subplots(n_rows, images_per_row, figsize=(images_per_row * 4, n_rows * 4))\n",
        "\n",
        "        # Flatten the axes array for easy iteration (in case of multiple rows)\n",
        "        axs = axs.flatten() if n_rows > 1 else [axs]\n",
        "\n",
        "        # Loop through the images and plot them\n",
        "        for i, img_file in enumerate(image_files_subset):\n",
        "            # Open the image\n",
        "            img = Image.open(os.path.join(results[0].save_dir, img_file))\n",
        "\n",
        "            # Display the image in the grid\n",
        "            axs[i].imshow(img)\n",
        "\n",
        "            # Turn off the axis labels\n",
        "            axs[i].axis('off')\n",
        "\n",
        "            # Set the filename as the title (use `splitext` to remove the file extension)\n",
        "            axs[i].set_title(os.path.splitext(img_file)[0], fontsize=8)\n",
        "\n",
        "        # Hide any remaining subplots (if the number of images is less than the number of subplots)\n",
        "        for i in range(len(image_files_subset), len(axs)):\n",
        "            axs[i].axis('off')\n",
        "\n",
        "        # Adjust layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save the figure with a specific name format\n",
        "        plt.savefig(f'{project}/predict/predict{epochs}_{count}.png', bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "# Call the function to save predictions\n",
        "save_predictions()\n"
      ],
      "metadata": {
        "id": "TMR3gRlLwM7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RUmmiBt4lXL"
      },
      "outputs": [],
      "source": [
        "predicts=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc95wLTF4B3s"
      },
      "outputs": [],
      "source": [
        "for file in os.listdir(f'{project}/predict'):\n",
        "  if os.path.isfile(f\"{project}/predict/{file}\"):\n",
        "    blob = bucket.blob(f\"{storageLocation}/predicts/{file}\")\n",
        "    blob.upload_from_filename(f\"{project}/predict/{file}\")\n",
        "    blob.make_public()\n",
        "    predicts.append(blob.public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ5L5tpg4htg"
      },
      "outputs": [],
      "source": [
        "today_ref.collection('Predict').add({\n",
        "    'files':predicts\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQWY9Bqbn7Hq"
      },
      "source": [
        "### Export Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YezH7LaIn7Hq"
      },
      "outputs": [],
      "source": [
        "format='onnx'\n",
        "model.export(format=format,keras=True,dynamic=True,simplify=True,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(format='saved_model',keras=True,simplify=True)"
      ],
      "metadata": {
        "id": "u5eZxysizn4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(format='tflite',keras=True,simplify=True)"
      ],
      "metadata": {
        "id": "sg9kZq3Hzuje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5HGcR1t5xnO"
      },
      "outputs": [],
      "source": [
        "blob = bucket.blob(f\"{storageLocation}/model/best.onnx\")\n",
        "blob.upload_from_filename(f\"{today_work_dirctory}/fruits/runs/{name}/weights/best.onnx\")\n",
        "blob.make_public()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blobsavedmodel = bucket.blob(f\"{storageLocation}/model/best_saved_model.pb\")\n",
        "blobsavedmodel.upload_from_filename(f\"{today_work_dirctory}/fruits/runs/{name}/weights/best_saved_model/saved_model.pb\")\n",
        "blobsavedmodel.make_public()"
      ],
      "metadata": {
        "id": "4Bk4X5AJz9Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blobtflite = bucket.blob(f\"{storageLocation}/model/best_float32.tflite\")\n",
        "blobtflite.upload_from_filename(f\"{today_work_dirctory}/fruits/runs/{name}/weights/best_saved_model/best_float32.tflite\")\n",
        "blobtflite.make_public()"
      ],
      "metadata": {
        "id": "mFNxSx0R0GnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0czVsQg5Kjr"
      },
      "outputs": [],
      "source": [
        "today_ref.collection('Model').add({\n",
        "    'format':format,\n",
        "    \"keras\":True,\n",
        "    \"dynamic\":True,\n",
        "    \"simplify\":True,\n",
        "    \"model\":blob.public_url\n",
        "})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}